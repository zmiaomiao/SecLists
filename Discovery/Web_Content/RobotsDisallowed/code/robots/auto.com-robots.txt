# /robots.txt file for http://www.auto.com
# See http://www.robotstxt.org/wc/norobots.html for documentation on how to use the robots.txt file
#
# See https://developers.google.com/webmasters/control-crawl-index/docs/robots_txt for best explanation
# of how Google interprets robots.txt.  The caveat being, Allow: is a Google-specific directive that other bots
# may ignore.

###  There can be one and only one 'User-agent: *' line in this file
User-agent: *
Disallow: /

User-agent: msnbot
User-agent: bingbot
# Crawl-delay is a Microsoft-specific directive
Crawl-delay: 1
Disallow: /*view=market_analysis
Disallow: /*.crt$
Disallow: /*.pdf$


User-agent: googlebot
Disallow: /*view=market_analysis
Disallow: /*.crt$
Disallow: /*.pdf$

User-agent: slurp
Disallow: /*view=market_analysis
Disallow: /*.crt$
Disallow: /*.pdf$
Disallow: /*cars-for-sale/*?page
Disallow: /*cars-for-sale/*?&page
