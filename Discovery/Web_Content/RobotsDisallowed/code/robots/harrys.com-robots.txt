# See http://www.robotstxt.org/wc/norobots.html for documentation on how to use the robots.txt file
#
# To ban all spiders from the entire site uncomment the next two lines:
# User-Agent: *
# Disallow: /

# robots.txt for https://www.harrys.com/

User-agent: *
Sitemap: https://www.harrys.com/sitemap.xml.gz
Disallow: /profile
Disallow: /users
Disallow: /users/
Disallow: /shipping_addresses
Disallow: /shipping_addresses/
Disallow: /billing_profile
Disallow: /billing_profile/
Disallow: /order/
Disallow: /orders/
Disallow: /api/
Disallow: /auth/

