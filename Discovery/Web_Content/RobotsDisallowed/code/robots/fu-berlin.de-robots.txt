# See http://www.robotstxt.org/wc/norobots.html for documentation on how to use the robots.txt file
#
# To ban all spiders from the entire site uncomment the next two lines:
# User-Agent: *
# Disallow: /

User-agent: *
Disallow: /_search
Disallow: /campusleben/_search
Disallow: /en/_search

#Temporaere Loesung: Sitemap inaktiv
#Sitemap: http://www.fu-berlin.de/sitemap/index.xml

