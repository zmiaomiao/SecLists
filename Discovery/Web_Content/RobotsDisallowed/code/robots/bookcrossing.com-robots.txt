
User-agent: *
Crawl-delay: 10
Disallow: /search/
Disallow: /search
Disallow: /membersearch/
Disallow: /fullsizecover/
Disallow: /forum/
Disallow: /forum2/
Disallow: /link/
Disallow: /browse/
Disallow: /hunt/
Disallow: /friend/
Disallow: /referral/
Disallow: /links/affiliates/
Disallow: /async/
Disallow: /Error
Disallow: /---/

user-agent: Googlebot
Disallow: /search/
Disallow: /search
Disallow: /membersearch/
Disallow: /link/
Disallow: /browse/
Disallow: /hunt/
Disallow: /friend/
Disallow: /referral/
Disallow: /links/affiliates/
Disallow: /async/
Disallow: /Error
Disallow: /---/

user-agent: msnbot
Disallow: /link/
Disallow: /friend/
Disallow: /referral/
Disallow: /links/affiliates/
Disallow: /---/

# Exabot doesn't play well with others
User-agent: Exabot*
Disallow: /

# Slurp needs to slow down and realize that subdomains are usually on the same server
User-agent: Slurp
Crawl-delay: 30
Disallow: /friend/
Disallow: /referral/
Disallow: /links/affiliates/
Disallow: /---/

# Yahoo
User-agent: Yahoo*
Disallow: /link/
Disallow: /referral/
Disallow: /friend/
Disallow: /links/affiliates/
Disallow: /---/

# Daum currently (2011-08) spiders a lot of .../.../h addresses (which don't exist)
user-agent: daumoa
Disallow: / 

user-agent: Baiduspider
Disallow: / 

User-agent: dotbot
Disallow: /

# Slow speedy down a bit
User-agent: Speedy
Crawl-Delay: 10
