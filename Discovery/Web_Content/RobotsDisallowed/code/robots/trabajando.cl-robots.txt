# Archivo robots.txt para NPP CL
# Bloqueamos primero lo global
# Fecha: 22-10-2014

#######################
# Los robots tienen acceso limitado a todo el sitio mediante el parámetro Disallow,
# excepto para las secciones, rutas o archivos especificados con el parámetro Allow

User-agent: *
Disallow: /
Allow: /searchresult
Allow: /trabajo-empleo
Allow: /noticias
Allow: /empleos/ofertas/
Allow: /noticias
Allow: /jobs/home
Allow: /canal/
Allow: /ingresar
Allow: /registro
Allow: /index.php
Allow: /home
Allow: /contenido
Allow: /*sitemap.xml$
Allow: /rss/canal/ofertasHome
Allow: /portales-comunidad
Allow: /empleos-trabajando/
Allow: /$

#######################

#
# Bloqueamos los motores que pueden realizar una indexacion inadecuada
# Podemos agregar otros que se conozca a nivel de servidor
#

User-agent: jobrapido
Disallow: /

User-agent: trovit
Disallow: /

User-agent: MSIECrawler
Disallow: /

User-agent: WebCopier
Disallow: /

User-agent: HTTrack
Disallow: /

User-agent: Microsoft.URL.Control
Disallow: /

User-agent: libwww
Disallow: /

User-agent: Mediapartners-Google
Disallow: /

#
# Motores más importantes que deseamos limitar en segundos
#

User-agent: noxtrumbot
Crawl-delay: 20
Allow: / 

User-agent: msnbot
Crawl-delay: 20
Allow: /

User-agent: Slurp
Crawl-delay: 20
Allow: /1305