# For all robots
User-agent: *
Disallow: /*.axd$
Disallow: /Meta/BASE-Suchergebnis
Disallow: /Auftragsstatus
Disallow: /LandingPageFactory
Disallow: /LegalTexts
Disallow: /Partner
Disallow: /base/?sort=
Disallow: /base/search
Disallow: /base/?listingDisplayMode
Disallow: /base/cart
Disallow: /base/checkout
Disallow: /base/my-account
Disallow: /*?q=

# Allow search crawlers to discover the sitemap
Sitemap: /sitemap.xml

# Block CazoodleBot as it does not present correct accept content headers
User-agent: CazoodleBot
Disallow: /

# Block MJ12bot as it is just noise
User-agent: MJ12bot
Disallow: /

# Block dotbot as it cannot parse base urls properly
User-agent: dotbot/1.0
Disallow: /

# Block Gigabot
User-agent: Gigabot
Disallow: /

# maximum rate is one page every 5 seconds
Request-rate: 1/5 

# 5 seconds between page requests
Crawl-delay: 5 

# only visit between 00:00 and 06:00 UTC 
Visit-time: 0000-0600 