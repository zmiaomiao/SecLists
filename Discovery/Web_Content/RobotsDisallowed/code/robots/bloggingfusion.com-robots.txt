# Robots TXT Generated by Blogging Fusion Blog Directory Bad Spider Bots Mod
# 
# Bad Spider Bots Mod detects bad bots that dont follow the rules and 
# requests to many pages at once either bringing the server down or to a slow crawl
# and logs their entries and requests to determine the spider bots behavoir 
# and effects on your website
# 
# Bad Spider Bots Mod v.1.0.0 
# Author: Blogging Fusion Blog Directory 
# Website: http://bloggingfusion.com/ 
# Licensed under the GNU/GPL: Version 3 
# You are free to use this spiderbot list as long as all copyright remains intact 
# 
# What does the robots.txt file do? 
# This file is to prevent the crawling and indexing of certain parts
# of your site by web crawlers and spiders run by sites like Yahoo!
# and Google. By telling these "robots" where not to go on your site,
# you save bandwidth and server resources. You also stop bad bots like email harvesters 
# or spider bot programs from stealing your whole website or content. 
#
# This file will be ignored unless it is at the root of your host:
# Proper Use:    http://example.com/robots.txt
# Not Permitted: http://example.com/site/robots.txt
#
# For more information about the robots.txt standard, see:
# http://www.robotstxt.org/wc/robots.html
#
# For syntax checking, see:
# http://www.sxw.org.uk/computing/robots/check.html
#
# For a list of all spider bots banned access to Blogging Fusion Blog Directoy 
# see the following url http://bloggingfusion.com/list-spiderbots/
#

User-agent: 008
Disallow: /

User-agent: 200PleaseBot
Disallow: /

User-agent: 360Spider
Disallow: /

User-agent: adbeat_bot
Disallow: /

User-agent: AhrefsBot
Disallow: /

User-agent: AOLbot/4.0
Disallow: /

User-agent: Baiduspider-image
Disallow: /

User-agent: bitlybot
Disallow: /

User-agent: Bot.AraTurka.com
Disallow: /

User-agent: Butterfly/1.0
Disallow: /

User-agent: ClarityDailyBot
Disallow: /

User-agent: CMS Crawler
Disallow: /

User-agent: Typhoeus
Disallow: /

User-agent: CRAZYWEBCRAWLER
Disallow: /

User-agent: diffbot
Disallow: /

User-agent: DomainAppender
Disallow: /

User-agent: WebIndex
Disallow: /

User-agent: Attribot/1.1
Disallow: /

User-agent: crawler4j
Disallow: /

User-agent: DomainSigmaCrawler
Disallow: /

User-agent: Domain Re-Animator Bot
Disallow: /

User-agent: Ezooms Robot
Disallow: /

User-agent: Google-HTTP-Java-Client
Disallow: /

User-agent: RavenCrawler
Disallow: /

User-agent: UptimeRobot/2.0
Disallow: /

User-agent: Exabot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: GrapeshotCrawler/2.0
Disallow: /

User-agent: linkdexbot/2.0
Disallow: /

