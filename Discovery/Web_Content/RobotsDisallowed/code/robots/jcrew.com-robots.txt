# robots.txt 2011/11/18 adamw $
#
# Site: J.Crew.com WWW
#
# This file is retrieved automatically by crawlers conforming to
# the Robots.txt standard. It defines what URLs should/shouldn't
# be indexed.
# See <URL:http://www.robotstxt.org/wc/exclusion.html#robotstxt>
#
# Format:
#       User-agent: <agent-string>
#       Disallow: <nothing> | <path>
# -----------------------------------------------------------------------------

User-agent: AdsBot-Google
Allow: /

User-agent: AdsBot-Google-Mobile
Allow: /

User-agent: *
Disallow: /account/
Disallow: /checkout/
Disallow: /AST/filterAsst/
Disallow: /help/include/inc_storelocator_right.jsp
Disallow: /index2.jsp

Disallow: /static/
Disallow: /c/
Disallow: /p/
Disallow: /data/
Disallow: /v/
Disallow: /api/
Disallow: /login/
Disallow: /register/
Disallow: /embed/
Disallow: /clienterror/
Disallow: /s/
Disallow: /feature-page/
Disallow: /size-charts/
Disallow: /sizecharts-module/
Disallow: /web-tracking/
Disallow: /r/

Sitemap: http://www.jcrew.com/sitemap.xml

