# rules for google
User-agent: Googlebot
# crawling is generally allowed
Disallow: 

# rules for bing/yahoo
User-agent: Bingbot
# crawling is generally allowed
Disallow:

# rules for ninja
User-agent: Ninjabot
# crawling is generally allowed
Disallow:

# rules for w3c linkchecker
User-Agent: W3C-checklink
# crawling is generally allowed
Disallow:

# rules for web archive
User-agent: ia_archiver
# crawling is generally allowed
Disallow:

# rules for all others
User-agent: *
# crawling is NOT allowed
Disallow: /

# general rules
# delay 1 sec between calls
Crawl-delay: 1
# only use the main domain for crawling
Host: tu-dresden.de
