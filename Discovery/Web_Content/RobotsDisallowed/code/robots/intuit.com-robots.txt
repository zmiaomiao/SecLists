# See http://www.robotstxt.org/wc/norobots.html for documentation on how to
# use the robots.txt file
#
# To ban all spiders from the entire site uncomment the next two lines:
# User-Agent: *
# Disallow: /
User-agent: sogou spider
Disallow: /
 
User-agent: Sogou web
spider/4.0(+http://www.sogou.com/docs/help/webmasters.htm#07) 
Disallow: /
 
User-agent: Sogou Pic
Spider/3.0(+http://www.sogou.com/docs/help/webmasters.htm#07)
Disallow: /
#YisouSpider  China
User-agent: YisouSpider
Disallow: /
 
User-agent: Baiduspider
Disallow: /
 
User-agent: Baiduspider+
Disallow: /
 
User-agent: Baiduspider+(+http://www.baidu.com/search/spider.htm)
Disallow: /
 
User-agent: Baiduspider/2.0;+http://www.baidu.com/search/spider.html
Disallow: /
 
User-agent: Baiduspider/2.0
Disallow: /
 
User-agent: +Baiduspider
Disallow: /
 
User-agent: +Baiduspider/2.0
Disallow: /
 
User-agent: +Baiduspider/2.0;++http://www.baidu.com/search/spider.html
Disallow: /
 
User-agent: Mozilla/5.0(compatible; Baiduspider/2.0;
+http://www.baidu.com/search/spider.html)
Disallow: /
 
User-agent: Baiduspider-image+(+http://www.baidu.com/search/spider.htm)
Disallow: /
 
User-agent: Mozilla/5.0 (compatible; Sosospider/2.0;
+http://help.soso.com/webspider.htm)
Disallow: /
 
User-agent: Mozilla/5.0 (compatible; JikeSpider;
+http://shoulu.jike.com/spider.html)
Disallow: /